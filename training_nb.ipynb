{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "NSA4JZk1x2XN"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate -U\n",
        "!pip install transformers[torch]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "-i33AT4MKlDR",
        "outputId": "4bebc7f8-4926-4d0f-d8f1-1ae8e8160993"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting accelerate\n",
            "  Downloading accelerate-0.31.0-py3-none-any.whl (309 kB)\n",
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/309.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m204.8/309.4 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m309.4/309.4 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.3.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.23.2)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.12.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m55.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.6.2)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, accelerate\n",
            "Successfully installed accelerate-0.31.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105\n",
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.41.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.23.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.3.0+cu121)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.31.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers[torch]) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers[torch]) (4.12.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->transformers[torch]) (12.5.40)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2024.6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->transformers[torch]) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->transformers[torch]) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final results at the end of the notebook"
      ],
      "metadata": {
        "id": "4muzTBKhUhi5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multi-Label Classification"
      ],
      "metadata": {
        "id": "NSA4JZk1x2XN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# HERE WE ARE TRAINING A MULTI-LABEL CLASSIFIER TO GET APPROPRIATE CATEGORIES\n",
        "# FOR THE GIVEN SENTENCE USING TRANSFER LEARNING ON BERT TRANSFORMER\n",
        "\n",
        "# DUE TO THE LARGE NUMBER OF CATEGORIES AND HOW MUCH MORE BETTER BERT IS AT\n",
        "# \"UNDERSTANDING\" CONTEXT I'VE AVOIDED USING SIMPLER MODELS LIKE SUPPORT VECTOR MACHINES\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# getting the dataset ready for training\n",
        "df = pd.read_csv('./category.csv')\n",
        "category_columns =  ['garage service', 'ease of booking', 'value for money', 'location',\n",
        "       'length of fitting', 'change of date', 'tyre quality', 'wait time',\n",
        "       'delivery punctuality', 'mobile fitter', 'advisor/agent service',\n",
        "       'advisoragent service', 'extra charges', 'damage', 'balancing',\n",
        "       'facilities', 'change of time', 'booking confusion', 'late notice',\n",
        "       'discounts', 'refund not actioned', 'refund timescale',\n",
        "       \"mobile fitter didn't arrive\", 'discount not applied',\n",
        "       'tyre agedot code', 'failed payment', 'incorrect tyres sent',\n",
        "       'call wait time', 'refund', 'no stock', 'response time',\n",
        "       'tyre age/dot code']\n",
        "\n",
        "\n",
        "X = df['sentence'].tolist()\n",
        "y = df[category_columns].values.tolist()\n",
        "# splitting\n",
        "X_train, X_eval, y_train, y_eval = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "fHOxvB-kDTiX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qwRVQT6u581",
        "outputId": "56134b8c-374c-45b1-fb37-5308b8adc03c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0', 'sentence', 'garage service', 'ease of booking',\n",
              "       'value for money', 'location', 'length of fitting', 'change of date',\n",
              "       'tyre quality', 'wait time', 'delivery punctuality', 'mobile fitter',\n",
              "       'advisor/agent service', 'advisoragent service', 'extra charges',\n",
              "       'damage', 'balancing', 'facilities', 'change of time',\n",
              "       'booking confusion', 'late notice', 'discounts', 'refund not actioned',\n",
              "       'refund timescale', 'mobile fitter didn't arrive',\n",
              "       'discount not applied', 'tyre agedot code', 'failed payment',\n",
              "       'incorrect tyres sent', 'call wait time', 'refund', 'no stock',\n",
              "       'response time', 'tyre age/dot code'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# using tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "train_encodings = tokenizer(X_train, truncation=True, padding=True, max_length=128)\n",
        "eval_encodings = tokenizer(X_eval, truncation=True, padding=True, max_length=128)"
      ],
      "metadata": {
        "id": "9XIgMubzvpgC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class MultiLabelDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.float)\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "# Create the dataset\n",
        "train_datasetz = MultiLabelDataset(train_encodings, y_train)\n",
        "eval_datasetz = MultiLabelDataset(eval_encodings, y_eval)"
      ],
      "metadata": {
        "id": "bjlUqWVqvstZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForSequenceClassification, Trainer, TrainingArguments\n",
        "\n",
        "# Load a pre-trained BERT model for sequence classification with a specific number of labels\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(category_columns), problem_type=\"multi_label_classification\")\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    warmup_steps=10,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy=\"epoch\"\n",
        ")\n",
        "\n",
        "# Define the trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_datasetz,\n",
        "    eval_dataset=eval_datasetz\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "id": "XtJ7BGjmvw8J",
        "outputId": "5bd6bf6b-9d91-4347-ccae-1bb556460e6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4875' max='4875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4875/4875 13:15, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.081100</td>\n",
              "      <td>0.085537</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.070200</td>\n",
              "      <td>0.067616</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.065200</td>\n",
              "      <td>0.062048</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=4875, training_loss=0.08302728243974539, metrics={'train_runtime': 795.1896, 'train_samples_per_second': 24.522, 'train_steps_per_second': 6.131, 'total_flos': 1283011891200000.0, 'train_loss': 0.08302728243974539, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForSequenceClassification\n",
        "\n",
        "new_sentences = [\"Good price, great service\"]\n",
        "new_encodings = tokenizer(new_sentences, truncation=True, padding=True, max_length=128)\n",
        "\n",
        "# testing\n",
        "model = BertForSequenceClassification.from_pretrained('./saved_model/category')\n",
        "trainer = Trainer(model)\n",
        "\n",
        "new_dataset = MultiLabelDataset(new_encodings, [[0]*len(category_columns)])\n",
        "predictions = trainer.predict(new_dataset)\n",
        "\n",
        "# convert to binary predictions to narrow down categories\n",
        "predicted_labels = (torch.sigmoid(torch.tensor(predictions[0])) > 0.4).int()\n",
        "\n",
        "# map predictions\n",
        "predicted_categories = [category_columns[i] for i in range(len(category_columns)) if predicted_labels[0][i] == 1]\n",
        "\n",
        "print(\"Predicted categories:\", predicted_categories)\n",
        "\n",
        "output_dir = \"./saved_model/category\"\n",
        "\n",
        "# # Save the model weights and tokenizer\n",
        "model.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "sArPpZyKyym4",
        "outputId": "205feea7-9f34-48ae-f558-125ec2fd55e1"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted categories: ['value for money']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./saved_model/category/tokenizer_config.json',\n",
              " './saved_model/category/special_tokens_map.json',\n",
              " './saved_model/category/vocab.txt',\n",
              " './saved_model/category/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sentiment Analyser"
      ],
      "metadata": {
        "id": "VEEvMDjUx88P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# WHILE TRAINING THE SENTIMENT ANALYSER I WANT TO PASS BOTH THE CATEGORY AND THE\n",
        "# SENTENCE BECAUSE THAT'S HOW WE KNOW IF THE SUB-SENTIMENT ANALYSER WORKS\n",
        "# THE REST IS ALMOST THE SAME AS THE PREVIOUS ONE\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('./sentiment.csv')\n",
        "\n",
        "\n",
        "#  combine 'sentence' and 'category' columns\n",
        "df['input'] = df['sentence'] + \" [CATEGORY] \" + df['category']\n",
        "\n",
        "# map sentiments to numerical values\n",
        "sentiment_mapping = {\"positive\": 1, \"negative\": 0}\n",
        "df['label'] = df['sentiment'].map(sentiment_mapping)\n",
        "\n",
        "# separate features and labels\n",
        "X = df['input'].tolist()\n",
        "y = df['label'].tolist()\n",
        "X_train, X_eval, y_train, y_eval = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "ULx8kPPnyZsr"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "train_encodings = tokenizer(X_train, truncation=True, padding=True, max_length=128)\n",
        "eval_encodings = tokenizer(X_eval, truncation=True, padding=True, max_length=128)"
      ],
      "metadata": {
        "id": "wNsjUAlcymGK"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class SentimentDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_datasetz = SentimentDataset(train_encodings, y_train)\n",
        "eval_datasetz = SentimentDataset(eval_encodings, y_eval)"
      ],
      "metadata": {
        "id": "Q7qRNcZ1ypPS"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForSequenceClassification, Trainer, TrainingArguments\n",
        "\n",
        "# load pretrained model\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
        "\n",
        "# arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./sentiment/results',\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    warmup_steps=10,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./sentiment/logs',\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy=\"epoch\"\n",
        ")\n",
        "\n",
        "# trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_datasetz,\n",
        "    eval_dataset=eval_datasetz\n",
        ")\n",
        "\n",
        "# train the model\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "S2TYPPoeyws7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "outputId": "d593a11f-93f4-495e-ade9-65ef2e35468d"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='8700' max='8700' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [8700/8700 26:26, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.367500</td>\n",
              "      <td>0.284297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.198400</td>\n",
              "      <td>0.241778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.098800</td>\n",
              "      <td>0.241979</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=8700, training_loss=0.24669371295757805, metrics={'train_runtime': 1587.0368, 'train_samples_per_second': 21.928, 'train_steps_per_second': 5.482, 'total_flos': 2289066181632000.0, 'train_loss': 0.24669371295757805, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_sentences = [\"Easy process but problems with booking a fitting appointment. The website made it easy to find the correct tyre specifications for my vehicle, and to place the order. I was offered a number of fitting options and chose ATS tyres, then selected a time slot to suit my convenience. Unfortunately the time slot I selected was not available at ATS and I had to wait a further two days for a convenient time, at which point the tyres were fitted quickly and professionally. Would have given five stars apart from being offered a fitting time that they couldn't honour.\"]\n",
        "new_categories = [\"change of time\", \"ease of booking\", \"length of fitting\", \"garage service\"]\n",
        "\n",
        "predicted_sentiments = []\n",
        "\n",
        "for category in new_categories:\n",
        "    # create new input for the current category\n",
        "    new_inputs = [f\"{sentence} [CATEGORY] {category}\" for sentence in new_sentences]\n",
        "\n",
        "    # tokenize the new inputs\n",
        "    new_encodings = tokenizer(new_inputs, truncation=True, padding=True, max_length=128)\n",
        "\n",
        "    # convert to dataset\n",
        "    new_dataset = SentimentDataset(new_encodings, [0] * len(new_inputs))  # Labels are dummy values\n",
        "\n",
        "    # get predictions\n",
        "    predictions = trainer.predict(new_dataset)\n",
        "\n",
        "    # 0:negative,1:positive\n",
        "    predicted_sentiments.append(torch.argmax(torch.tensor(predictions[0]), dim=1).tolist())\n",
        "\n",
        "# map numerical predictions back to sentiment labels\n",
        "reverse_sentiment_mapping = {v: k for k, v in sentiment_mapping.items()}\n",
        "predicted_labels = [[reverse_sentiment_mapping[sentiment] for sentiment in sentiments] for sentiments in predicted_sentiments]\n",
        "\n",
        "print(\"Predicted sentiments for each category:\")\n",
        "for category, sentiments in zip(new_categories, predicted_labels):\n",
        "    print(f\"{category}: {sentiments}\")\n",
        "\n",
        "output_dir = \"./saved_model/sentiment\"\n",
        "\n",
        "# save the model weights and tokenizer\n",
        "model.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "spPJ7S_gATwn",
        "outputId": "0947ea6e-4882-4762-f030-d9483f1d47e7"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted sentiments for each category:\n",
            "change of time: ['negative']\n",
            "ease of booking: ['positive']\n",
            "length of fitting: ['positive']\n",
            "garage service: ['positive']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./saved_model/sentiment/tokenizer_config.json',\n",
              " './saved_model/sentiment/special_tokens_map.json',\n",
              " './saved_model/sentiment/vocab.txt',\n",
              " './saved_model/sentiment/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Combining Models\n"
      ],
      "metadata": {
        "id": "mqzRl6EOCd45"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# NOW THAT WE HAVE TRAINED OUR TWO MODELS AND HAVE THE APPROPRIATE WEIGHTS READY\n",
        "# WE CAN COMBINE THEM TOGETHER\n",
        "# HERE WE PASS THE INPUT STRING\n",
        "  # THROUGH THE CATEGORY MULTI-LABEL CLASSIFIER FIRST\n",
        "  # WE ITERATIVELY PASS THE OUTPUT ALONG WITH THE INPUT STRING TO THE SENTIMENT ANALYSER\n",
        "  # AND GET THE FINAL OUTPUT IN A DICTIONARY\n",
        "\n",
        "from transformers import BertForSequenceClassification, BertTokenizer\n",
        "import torch\n",
        "\n",
        "model1 = BertForSequenceClassification.from_pretrained('./saved_model/category')\n",
        "model2 = BertForSequenceClassification.from_pretrained('./saved_model/sentiment')\n",
        "trainer1 = Trainer(model1)\n",
        "trainer2 = Trainer(model2)\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "sentiment_mapping = {\"positive\": 1, \"negative\": 0}\n",
        "\n",
        "# Define categories\n",
        "category_columns = ['garage service', 'ease of booking', 'value for money', 'location',\n",
        "       'length of fitting', 'change of date', 'tyre quality', 'wait time',\n",
        "       'delivery punctuality', 'mobile fitter', 'advisor/agent service',\n",
        "       'advisoragent service', 'extra charges', 'damage', 'balancing',\n",
        "       'facilities', 'change of time', 'booking confusion', 'late notice',\n",
        "       'discounts', 'refund not actioned', 'refund timescale',\n",
        "       \"mobile fitter didn't arrive\", 'discount not applied',\n",
        "       'tyre agedot code', 'failed payment', 'incorrect tyres sent',\n",
        "       'call wait time', 'refund', 'no stock', 'response time',\n",
        "       'tyre age/dot code']\n",
        "\n",
        "def predict_sentiment(input_string):\n",
        "    new_encodings = tokenizer(input_string, truncation=True, padding=True, max_length=128)\n",
        "\n",
        "    new_dataset1 = MultiLabelDataset(new_encodings, [[0]*len(category_columns)])\n",
        "    predictions = trainer1.predict(new_dataset1)\n",
        "\n",
        "    # convert to binary predictions to narrow down categories\n",
        "    predicted_labels = (torch.sigmoid(torch.tensor(predictions[0])) > 0.4).int()\n",
        "    #    map predictions\n",
        "    predicted_categories = [category_columns[i] for i in range(len(category_columns)) if predicted_labels[0][i] == 1]\n",
        "    if not predicted_categories:\n",
        "      return None\n",
        "\n",
        "    predicted_sentiments = []\n",
        "\n",
        "    for category in predicted_categories:\n",
        "      # create new input for the current category\n",
        "      new_inputs = [f\"{sentence} [CATEGORY] {category}\" for sentence in input_string]\n",
        "\n",
        "      # tokenize the new inputs\n",
        "      new_encodings = tokenizer(new_inputs, truncation=True, padding=True, max_length=128)\n",
        "      new_dataset = SentimentDataset(new_encodings, [0] * len(new_inputs))  # labels are dummy values\n",
        "\n",
        "      # get predictions\n",
        "      predictions = trainer2.predict(new_dataset)\n",
        "\n",
        "      # 0:negative,1:positive\n",
        "      predicted_sentiments.append(torch.argmax(torch.tensor(predictions[0]), dim=1).tolist())\n",
        "\n",
        "    # map numerical predictions back to sentiment labels\n",
        "    reverse_sentiment_mapping = {v: k for k, v in sentiment_mapping.items()}\n",
        "    predicted_labels = [[reverse_sentiment_mapping[sentiment] for sentiment in sentiments] for sentiments in predicted_sentiments]\n",
        "\n",
        "    print(\"Predicted sentiments for each category:\")\n",
        "    output = {}\n",
        "    for category, sentiments in zip(predicted_categories, predicted_labels):\n",
        "      output[category] = sentiments\n",
        "\n",
        "    return output\n",
        "\n",
        "# THE INPUT STRING\n",
        "input_string = [[\"Good price, great service\"],[\"Was messed around quite a lot - times rearranged due to tyres not being delivered, then put back to the original appointment - without cancellung the changed one. Will go directly through the garage next time. [REDACTED] messed me about too much for the same price as the garage would have given without them.\"],[\"Excellent service and saved a few pounds Will definitely be using [REDACTED] again.\"],[\"Competitive prices and consistently excellent. This has been the case for many years. No problems with the tyres being sent on time to the fitters or the fitters themselves.\"]]\n",
        "\n",
        "for st in input_string:\n",
        "  print(st)\n",
        "  predicted_sentiments = predict_sentiment(st)\n",
        "  print(predicted_sentiments)\n",
        "  print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "2poI2Bm_ChK7",
        "outputId": "0ea01e90-578c-44c3-e58e-f16e5371b379"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Good price, great service']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted sentiments for each category:\n",
            "{'value for money': ['positive']}\n",
            "\n",
            "\n",
            "['Was messed around quite a lot - times rearranged due to tyres not being delivered, then put back to the original appointment - without cancellung the changed one. Will go directly through the garage next time. [REDACTED] messed me about too much for the same price as the garage would have given without them.']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted sentiments for each category:\n",
            "{'value for money': ['negative'], 'change of date': ['negative'], 'delivery punctuality': ['negative']}\n",
            "\n",
            "\n",
            "['Excellent service and saved a few pounds Will definitely be using [REDACTED] again.']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted sentiments for each category:\n",
            "{'value for money': ['positive']}\n",
            "\n",
            "\n",
            "['Competitive prices and consistently excellent. This has been the case for many years. No problems with the tyres being sent on time to the fitters or the fitters themselves.']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted sentiments for each category:\n",
            "{'value for money': ['positive'], 'delivery punctuality': ['positive']}\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/saved_model.zip /content/saved_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyMjzfg7VBsB",
        "outputId": "5e2629dd-975d-42d4-ed6b-7d67e1e37816"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/saved_model/ (stored 0%)\n",
            "  adding: content/saved_model/category/ (stored 0%)\n",
            "  adding: content/saved_model/category/config.json (deflated 65%)\n",
            "  adding: content/saved_model/category/model.safetensors (deflated 7%)\n",
            "  adding: content/saved_model/category/special_tokens_map.json (deflated 42%)\n",
            "  adding: content/saved_model/category/vocab.txt (deflated 53%)\n",
            "  adding: content/saved_model/category/tokenizer_config.json (deflated 75%)\n",
            "  adding: content/saved_model/sentiment/ (stored 0%)\n",
            "  adding: content/saved_model/sentiment/config.json (deflated 49%)\n",
            "  adding: content/saved_model/sentiment/model.safetensors (deflated 7%)\n",
            "  adding: content/saved_model/sentiment/special_tokens_map.json (deflated 42%)\n",
            "  adding: content/saved_model/sentiment/vocab.txt (deflated 53%)\n",
            "  adding: content/saved_model/sentiment/tokenizer_config.json (deflated 75%)\n"
          ]
        }
      ]
    }
  ]
}