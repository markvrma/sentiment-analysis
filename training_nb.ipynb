{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "-i33AT4MKlDR",
        "outputId": "4bebc7f8-4926-4d0f-d8f1-1ae8e8160993"
      },
      "outputs": [],
      "source": [
        "!pip install accelerate -U\n",
        "!pip install transformers[torch]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4muzTBKhUhi5"
      },
      "source": [
        "# Final results at the end of the notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSA4JZk1x2XN"
      },
      "source": [
        "# Multi-Label Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fHOxvB-kDTiX"
      },
      "outputs": [],
      "source": [
        "# HERE WE ARE TRAINING A MULTI-LABEL CLASSIFIER TO GET APPROPRIATE CATEGORIES\n",
        "# FOR THE GIVEN SENTENCE USING TRANSFER LEARNING ON BERT TRANSFORMER\n",
        "\n",
        "# DUE TO THE LARGE NUMBER OF CATEGORIES AND HOW MUCH MORE BETTER BERT IS AT\n",
        "# \"UNDERSTANDING\" CONTEXT I'VE AVOIDED USING SIMPLER MODELS LIKE SUPPORT VECTOR MACHINES\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# getting the dataset ready for training\n",
        "df = pd.read_csv('./category.csv')\n",
        "category_columns =  ['garage service', 'ease of booking', 'value for money', 'location',\n",
        "       'length of fitting', 'change of date', 'tyre quality', 'wait time',\n",
        "       'delivery punctuality', 'mobile fitter', 'advisor/agent service',\n",
        "       'advisoragent service', 'extra charges', 'damage', 'balancing',\n",
        "       'facilities', 'change of time', 'booking confusion', 'late notice',\n",
        "       'discounts', 'refund not actioned', 'refund timescale',\n",
        "       \"mobile fitter didn't arrive\", 'discount not applied',\n",
        "       'tyre agedot code', 'failed payment', 'incorrect tyres sent',\n",
        "       'call wait time', 'refund', 'no stock', 'response time',\n",
        "       'tyre age/dot code']\n",
        "\n",
        "\n",
        "X = df['sentence'].tolist()\n",
        "y = df[category_columns].values.tolist()\n",
        "# splitting\n",
        "X_train, X_eval, y_train, y_eval = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qwRVQT6u581",
        "outputId": "56134b8c-374c-45b1-fb37-5308b8adc03c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0', 'sentence', 'garage service', 'ease of booking',\n",
              "       'value for money', 'location', 'length of fitting', 'change of date',\n",
              "       'tyre quality', 'wait time', 'delivery punctuality', 'mobile fitter',\n",
              "       'advisor/agent service', 'advisoragent service', 'extra charges',\n",
              "       'damage', 'balancing', 'facilities', 'change of time',\n",
              "       'booking confusion', 'late notice', 'discounts', 'refund not actioned',\n",
              "       'refund timescale', 'mobile fitter didn't arrive',\n",
              "       'discount not applied', 'tyre agedot code', 'failed payment',\n",
              "       'incorrect tyres sent', 'call wait time', 'refund', 'no stock',\n",
              "       'response time', 'tyre age/dot code'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9XIgMubzvpgC"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# using tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "train_encodings = tokenizer(X_train, truncation=True, padding=True, max_length=128)\n",
        "eval_encodings = tokenizer(X_eval, truncation=True, padding=True, max_length=128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bjlUqWVqvstZ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class MultiLabelDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.float)\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "# Create the dataset\n",
        "train_datasetz = MultiLabelDataset(train_encodings, y_train)\n",
        "eval_datasetz = MultiLabelDataset(eval_encodings, y_eval)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "id": "XtJ7BGjmvw8J",
        "outputId": "5bd6bf6b-9d91-4347-ccae-1bb556460e6b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4875' max='4875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4875/4875 13:15, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.081100</td>\n",
              "      <td>0.085537</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.070200</td>\n",
              "      <td>0.067616</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.065200</td>\n",
              "      <td>0.062048</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=4875, training_loss=0.08302728243974539, metrics={'train_runtime': 795.1896, 'train_samples_per_second': 24.522, 'train_steps_per_second': 6.131, 'total_flos': 1283011891200000.0, 'train_loss': 0.08302728243974539, 'epoch': 3.0})"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import BertForSequenceClassification, Trainer, TrainingArguments\n",
        "\n",
        "# Load a pre-trained BERT model for sequence classification with a specific number of labels\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(category_columns), problem_type=\"multi_label_classification\")\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    warmup_steps=10,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy=\"epoch\"\n",
        ")\n",
        "\n",
        "# Define the trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_datasetz,\n",
        "    eval_dataset=eval_datasetz\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "sArPpZyKyym4",
        "outputId": "205feea7-9f34-48ae-f558-125ec2fd55e1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted categories: ['value for money']\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "('./saved_model/category/tokenizer_config.json',\n",
              " './saved_model/category/special_tokens_map.json',\n",
              " './saved_model/category/vocab.txt',\n",
              " './saved_model/category/added_tokens.json')"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import BertForSequenceClassification\n",
        "\n",
        "new_sentences = [\"Good price, great service\"]\n",
        "new_encodings = tokenizer(new_sentences, truncation=True, padding=True, max_length=128)\n",
        "\n",
        "# testing\n",
        "model = BertForSequenceClassification.from_pretrained('./saved_model/category')\n",
        "trainer = Trainer(model)\n",
        "\n",
        "new_dataset = MultiLabelDataset(new_encodings, [[0]*len(category_columns)])\n",
        "predictions = trainer.predict(new_dataset)\n",
        "\n",
        "# convert to binary predictions to narrow down categories\n",
        "predicted_labels = (torch.sigmoid(torch.tensor(predictions[0])) > 0.4).int()\n",
        "\n",
        "# map predictions\n",
        "predicted_categories = [category_columns[i] for i in range(len(category_columns)) if predicted_labels[0][i] == 1]\n",
        "\n",
        "print(\"Predicted categories:\", predicted_categories)\n",
        "\n",
        "output_dir = \"./saved_model/category\"\n",
        "\n",
        "# # Save the model weights and tokenizer\n",
        "model.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEEvMDjUx88P"
      },
      "source": [
        "# Sentiment Analyser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "ULx8kPPnyZsr"
      },
      "outputs": [],
      "source": [
        "# WHILE TRAINING THE SENTIMENT ANALYSER I WANT TO PASS BOTH THE CATEGORY AND THE\n",
        "# SENTENCE BECAUSE THAT'S HOW WE KNOW IF THE SUB-SENTIMENT ANALYSER WORKS\n",
        "# THE REST IS ALMOST THE SAME AS THE PREVIOUS ONE\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('./sentiment.csv')\n",
        "\n",
        "\n",
        "#  combine 'sentence' and 'category' columns\n",
        "df['input'] = df['sentence'] + \" [CATEGORY] \" + df['category']\n",
        "\n",
        "# map sentiments to numerical values\n",
        "sentiment_mapping = {\"positive\": 1, \"negative\": 0}\n",
        "df['label'] = df['sentiment'].map(sentiment_mapping)\n",
        "\n",
        "# separate features and labels\n",
        "X = df['input'].tolist()\n",
        "y = df['label'].tolist()\n",
        "X_train, X_eval, y_train, y_eval = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "wNsjUAlcymGK"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "train_encodings = tokenizer(X_train, truncation=True, padding=True, max_length=128)\n",
        "eval_encodings = tokenizer(X_eval, truncation=True, padding=True, max_length=128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "Q7qRNcZ1ypPS"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class SentimentDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_datasetz = SentimentDataset(train_encodings, y_train)\n",
        "eval_datasetz = SentimentDataset(eval_encodings, y_eval)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "id": "S2TYPPoeyws7",
        "outputId": "d593a11f-93f4-495e-ade9-65ef2e35468d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='8700' max='8700' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [8700/8700 26:26, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.367500</td>\n",
              "      <td>0.284297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.198400</td>\n",
              "      <td>0.241778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.098800</td>\n",
              "      <td>0.241979</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=8700, training_loss=0.24669371295757805, metrics={'train_runtime': 1587.0368, 'train_samples_per_second': 21.928, 'train_steps_per_second': 5.482, 'total_flos': 2289066181632000.0, 'train_loss': 0.24669371295757805, 'epoch': 3.0})"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import BertForSequenceClassification, Trainer, TrainingArguments\n",
        "\n",
        "# load pretrained model\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
        "\n",
        "# arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./sentiment/results',\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    warmup_steps=10,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./sentiment/logs',\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy=\"epoch\"\n",
        ")\n",
        "\n",
        "# trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_datasetz,\n",
        "    eval_dataset=eval_datasetz\n",
        ")\n",
        "\n",
        "# train the model\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "spPJ7S_gATwn",
        "outputId": "0947ea6e-4882-4762-f030-d9483f1d47e7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted sentiments for each category:\n",
            "change of time: ['negative']\n",
            "ease of booking: ['positive']\n",
            "length of fitting: ['positive']\n",
            "garage service: ['positive']\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "('./saved_model/sentiment/tokenizer_config.json',\n",
              " './saved_model/sentiment/special_tokens_map.json',\n",
              " './saved_model/sentiment/vocab.txt',\n",
              " './saved_model/sentiment/added_tokens.json')"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "new_sentences = [\"Easy process but problems with booking a fitting appointment. The website made it easy to find the correct tyre specifications for my vehicle, and to place the order. I was offered a number of fitting options and chose ATS tyres, then selected a time slot to suit my convenience. Unfortunately the time slot I selected was not available at ATS and I had to wait a further two days for a convenient time, at which point the tyres were fitted quickly and professionally. Would have given five stars apart from being offered a fitting time that they couldn't honour.\"]\n",
        "new_categories = [\"change of time\", \"ease of booking\", \"length of fitting\", \"garage service\"]\n",
        "\n",
        "predicted_sentiments = []\n",
        "\n",
        "for category in new_categories:\n",
        "    # create new input for the current category\n",
        "    new_inputs = [f\"{sentence} [CATEGORY] {category}\" for sentence in new_sentences]\n",
        "\n",
        "    # tokenize the new inputs\n",
        "    new_encodings = tokenizer(new_inputs, truncation=True, padding=True, max_length=128)\n",
        "\n",
        "    # convert to dataset\n",
        "    new_dataset = SentimentDataset(new_encodings, [0] * len(new_inputs))  # Labels are dummy values\n",
        "\n",
        "    # get predictions\n",
        "    predictions = trainer.predict(new_dataset)\n",
        "\n",
        "    # 0:negative,1:positive\n",
        "    predicted_sentiments.append(torch.argmax(torch.tensor(predictions[0]), dim=1).tolist())\n",
        "\n",
        "# map numerical predictions back to sentiment labels\n",
        "reverse_sentiment_mapping = {v: k for k, v in sentiment_mapping.items()}\n",
        "predicted_labels = [[reverse_sentiment_mapping[sentiment] for sentiment in sentiments] for sentiments in predicted_sentiments]\n",
        "\n",
        "print(\"Predicted sentiments for each category:\")\n",
        "for category, sentiments in zip(new_categories, predicted_labels):\n",
        "    print(f\"{category}: {sentiments}\")\n",
        "\n",
        "output_dir = \"./saved_model/sentiment\"\n",
        "\n",
        "# save the model weights and tokenizer\n",
        "model.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqzRl6EOCd45"
      },
      "source": [
        "# Combining Models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "2poI2Bm_ChK7",
        "outputId": "0ea01e90-578c-44c3-e58e-f16e5371b379"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Good price, great service']\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted sentiments for each category:\n",
            "{'value for money': ['positive']}\n",
            "\n",
            "\n",
            "['Was messed around quite a lot - times rearranged due to tyres not being delivered, then put back to the original appointment - without cancellung the changed one. Will go directly through the garage next time. [REDACTED] messed me about too much for the same price as the garage would have given without them.']\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted sentiments for each category:\n",
            "{'value for money': ['negative'], 'change of date': ['negative'], 'delivery punctuality': ['negative']}\n",
            "\n",
            "\n",
            "['Excellent service and saved a few pounds Will definitely be using [REDACTED] again.']\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted sentiments for each category:\n",
            "{'value for money': ['positive']}\n",
            "\n",
            "\n",
            "['Competitive prices and consistently excellent. This has been the case for many years. No problems with the tyres being sent on time to the fitters or the fitters themselves.']\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted sentiments for each category:\n",
            "{'value for money': ['positive'], 'delivery punctuality': ['positive']}\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# NOW THAT WE HAVE TRAINED OUR TWO MODELS AND HAVE THE APPROPRIATE WEIGHTS READY\n",
        "# WE CAN COMBINE THEM TOGETHER\n",
        "# HERE WE PASS THE INPUT STRING\n",
        "  # THROUGH THE CATEGORY MULTI-LABEL CLASSIFIER FIRST\n",
        "  # WE ITERATIVELY PASS THE OUTPUT ALONG WITH THE INPUT STRING TO THE SENTIMENT ANALYSER\n",
        "  # AND GET THE FINAL OUTPUT IN A DICTIONARY\n",
        "\n",
        "from transformers import BertForSequenceClassification, BertTokenizer\n",
        "import torch\n",
        "\n",
        "model1 = BertForSequenceClassification.from_pretrained('./saved_model/category')\n",
        "model2 = BertForSequenceClassification.from_pretrained('./saved_model/sentiment')\n",
        "trainer1 = Trainer(model1)\n",
        "trainer2 = Trainer(model2)\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "sentiment_mapping = {\"positive\": 1, \"negative\": 0}\n",
        "\n",
        "# Define categories\n",
        "category_columns = ['garage service', 'ease of booking', 'value for money', 'location',\n",
        "       'length of fitting', 'change of date', 'tyre quality', 'wait time',\n",
        "       'delivery punctuality', 'mobile fitter', 'advisor/agent service',\n",
        "       'advisoragent service', 'extra charges', 'damage', 'balancing',\n",
        "       'facilities', 'change of time', 'booking confusion', 'late notice',\n",
        "       'discounts', 'refund not actioned', 'refund timescale',\n",
        "       \"mobile fitter didn't arrive\", 'discount not applied',\n",
        "       'tyre agedot code', 'failed payment', 'incorrect tyres sent',\n",
        "       'call wait time', 'refund', 'no stock', 'response time',\n",
        "       'tyre age/dot code']\n",
        "\n",
        "def predict_sentiment(input_string):\n",
        "    new_encodings = tokenizer(input_string, truncation=True, padding=True, max_length=128)\n",
        "\n",
        "    new_dataset1 = MultiLabelDataset(new_encodings, [[0]*len(category_columns)])\n",
        "    predictions = trainer1.predict(new_dataset1)\n",
        "\n",
        "    # convert to binary predictions to narrow down categories\n",
        "    predicted_labels = (torch.sigmoid(torch.tensor(predictions[0])) > 0.4).int()\n",
        "    #    map predictions\n",
        "    predicted_categories = [category_columns[i] for i in range(len(category_columns)) if predicted_labels[0][i] == 1]\n",
        "    if not predicted_categories:\n",
        "      return None\n",
        "\n",
        "    predicted_sentiments = []\n",
        "\n",
        "    for category in predicted_categories:\n",
        "      # create new input for the current category\n",
        "      new_inputs = [f\"{sentence} [CATEGORY] {category}\" for sentence in input_string]\n",
        "\n",
        "      # tokenize the new inputs\n",
        "      new_encodings = tokenizer(new_inputs, truncation=True, padding=True, max_length=128)\n",
        "      new_dataset = SentimentDataset(new_encodings, [0] * len(new_inputs))  # labels are dummy values\n",
        "\n",
        "      # get predictions\n",
        "      predictions = trainer2.predict(new_dataset)\n",
        "\n",
        "      # 0:negative,1:positive\n",
        "      predicted_sentiments.append(torch.argmax(torch.tensor(predictions[0]), dim=1).tolist())\n",
        "\n",
        "    # map numerical predictions back to sentiment labels\n",
        "    reverse_sentiment_mapping = {v: k for k, v in sentiment_mapping.items()}\n",
        "    predicted_labels = [[reverse_sentiment_mapping[sentiment] for sentiment in sentiments] for sentiments in predicted_sentiments]\n",
        "\n",
        "    print(\"Predicted sentiments for each category:\")\n",
        "    output = {}\n",
        "    for category, sentiments in zip(predicted_categories, predicted_labels):\n",
        "      output[category] = sentiments\n",
        "\n",
        "    return output\n",
        "\n",
        "# THE INPUT STRING\n",
        "input_string = [[\"Good price, great service\"],[\"Was messed around quite a lot - times rearranged due to tyres not being delivered, then put back to the original appointment - without cancellung the changed one. Will go directly through the garage next time. [REDACTED] messed me about too much for the same price as the garage would have given without them.\"],[\"Excellent service and saved a few pounds Will definitely be using [REDACTED] again.\"],[\"Competitive prices and consistently excellent. This has been the case for many years. No problems with the tyres being sent on time to the fitters or the fitters themselves.\"]]\n",
        "\n",
        "for st in input_string:\n",
        "  print(st)\n",
        "  predicted_sentiments = predict_sentiment(st)\n",
        "  print(predicted_sentiments)\n",
        "  print(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyMjzfg7VBsB",
        "outputId": "5e2629dd-975d-42d4-ed6b-7d67e1e37816"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  adding: content/saved_model/ (stored 0%)\n",
            "  adding: content/saved_model/category/ (stored 0%)\n",
            "  adding: content/saved_model/category/config.json (deflated 65%)\n",
            "  adding: content/saved_model/category/model.safetensors (deflated 7%)\n",
            "  adding: content/saved_model/category/special_tokens_map.json (deflated 42%)\n",
            "  adding: content/saved_model/category/vocab.txt (deflated 53%)\n",
            "  adding: content/saved_model/category/tokenizer_config.json (deflated 75%)\n",
            "  adding: content/saved_model/sentiment/ (stored 0%)\n",
            "  adding: content/saved_model/sentiment/config.json (deflated 49%)\n",
            "  adding: content/saved_model/sentiment/model.safetensors (deflated 7%)\n",
            "  adding: content/saved_model/sentiment/special_tokens_map.json (deflated 42%)\n",
            "  adding: content/saved_model/sentiment/vocab.txt (deflated 53%)\n",
            "  adding: content/saved_model/sentiment/tokenizer_config.json (deflated 75%)\n"
          ]
        }
      ],
      "source": [
        "!zip -r /content/saved_model.zip /content/saved_model"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "NSA4JZk1x2XN"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
